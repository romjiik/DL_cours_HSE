{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "hse_dl_year": "2021-fall",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvW8-J6we6By"
      },
      "source": [
        "# Обучение нейросетей — оптимизация и регуляризация\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ecMva_Ge6B0"
      },
      "source": [
        "На это семинаре будет необходимо \n",
        "1. реализовать Dropout-слой и проследить его влияние на обобщающую способность сети \n",
        "2. реализовать BatchNormalization-слой"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQZ-_wUwe6B0"
      },
      "source": [
        "## Dropout\n",
        "\n",
        "Как всегда будем экспериментировать на датасете MNIST. MNIST является стандартным бенчмарк-датасетом, и его можно подгрузить средствами pytorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4S5PFg5e6B1"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "from torch.utils.data.sampler import SubsetRandomSampler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed: int):\n",
        "    import random, os\n",
        "    import numpy as np\n",
        "    import torch\n",
        "    \n",
        "    torch.use_deterministic_algorithms(True)\n",
        "    \n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True"
      ],
      "metadata": {
        "id": "G78D4U8VPlXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "need_run_tests_and_training = 'google.colab' in str(get_ipython())\n",
        "need_run_tests_and_training"
      ],
      "metadata": {
        "id": "RDycPIfrP_f2",
        "outputId": "1e0cb648-f0df-414d-e47f-1f1ef3bd3757",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EuePwt3e6B5"
      },
      "source": [
        "input_size = 784\n",
        "num_classes = 10\n",
        "batch_size = 128\n",
        "\n",
        "train_dataset = dsets.MNIST(root='./MNIST/', \n",
        "                                   train=True, \n",
        "                                   transform=transforms.ToTensor(),\n",
        "                                   download=True)\n",
        "\n",
        "test_dataset = dsets.MNIST(root='./MNIST/', \n",
        "                                  train=False, \n",
        "                                  transform=transforms.ToTensor())\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
        "                                          batch_size=batch_size, \n",
        "                                          shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUFeuDtfe6B9"
      },
      "source": [
        "Определим ряд стандартных функций с прошлых семинаров"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_rmaGJQe6B9"
      },
      "source": [
        "def train_epoch(model, optimizer, batchsize=32):    \n",
        "    loss_log, acc_log = [], []\n",
        "    model.train()\n",
        "    for batch_num, (x_batch, y_batch) in enumerate(train_loader):\n",
        "        data = x_batch\n",
        "        target = y_batch\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        pred = torch.max(output, 1)[1]\n",
        "        acc = torch.eq(pred, y_batch).float().mean()\n",
        "        acc_log.append(acc)\n",
        "        \n",
        "        loss = F.nll_loss(output, target).cpu()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        loss = loss.item()\n",
        "        loss_log.append(loss)\n",
        "    return loss_log, acc_log    \n",
        "\n",
        "def test(model):\n",
        "    loss_log, acc_log = [], []\n",
        "    model.eval()\n",
        "    for batch_num, (x_batch, y_batch) in enumerate(test_loader):    \n",
        "        data = x_batch\n",
        "        target = y_batch\n",
        "\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target).cpu()\n",
        "\n",
        "        pred = torch.max(output, 1)[1]\n",
        "        acc = torch.eq(pred, y_batch).float().mean()\n",
        "        acc_log.append(acc)\n",
        "        \n",
        "        loss = loss.item()\n",
        "        loss_log.append(loss)\n",
        "    return loss_log, acc_log\n",
        "\n",
        "def plot_history(train_history, val_history, title='loss'):\n",
        "    plt.figure()\n",
        "    plt.title('{}'.format(title))\n",
        "    plt.plot(train_history, label='train', zorder=1)\n",
        "    \n",
        "    points = np.array(val_history)\n",
        "    \n",
        "    plt.scatter(points[:, 0], points[:, 1], marker='+', s=180, c='orange', label='val', zorder=2)\n",
        "    plt.xlabel('train steps')\n",
        "    \n",
        "    plt.legend(loc='best')\n",
        "    plt.grid()\n",
        "\n",
        "    plt.show()\n",
        "    \n",
        "def train(model, opt, n_epochs):\n",
        "\n",
        "    if not need_run_tests_and_training:\n",
        "        return\n",
        "\n",
        "    train_log, train_acc_log = [], []\n",
        "    val_log, val_acc_log = [], []\n",
        "\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        print(\"Epoch {0} of {1}\".format(epoch, n_epochs))\n",
        "        train_loss, train_acc = train_epoch(model, opt, batchsize=batch_size)\n",
        "\n",
        "        val_loss, val_acc = test(model)\n",
        "\n",
        "        train_log.extend(train_loss)\n",
        "        train_acc_log.extend(train_acc)\n",
        "\n",
        "        steps = train_dataset.train_labels.shape[0] / batch_size\n",
        "        val_log.append((steps * (epoch + 1), np.mean(val_loss)))\n",
        "        val_acc_log.append((steps * (epoch + 1), np.mean(val_acc)))\n",
        "        \n",
        "        clear_output()\n",
        "        plot_history(train_log, val_log)    \n",
        "        plot_history(train_acc_log, val_acc_log, title='accuracy')   \n",
        "        \n",
        "        print(\"Epoch: {2}, val loss: {0}, val accuracy: {1}\".format(np.mean(val_loss), np.mean(val_acc), epoch))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjhiP5h-e6CA"
      },
      "source": [
        "Создайте простейшую однослойную модель - однослойную полносвязную сеть и обучите ее с параметрами оптимизации, заданными ниже."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLB2iHNke6CB"
      },
      "source": [
        "   \n",
        "model = nn.Sequential(\n",
        "                    nn.Flatten(1),\n",
        "                    nn.Linear(input_size, num_classes),\n",
        "                    nn.LogSoftmax(dim=-1)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8ppSMDae6CE"
      },
      "source": [
        "opt = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
        "train(model, opt, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7smJP34Pe6CH"
      },
      "source": [
        "Параметром обученной нейросети является матрица весов, в которой каждому классу соответствует один из 784-мерных столбцов. Визуализируйте обученные векторы для каждого из классов, сделав их двумерными изображениями 28-28. Для визуализации можно воспользоваться кодом для визуализации MNIST-картинок с предыдущих семинаров."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model._modules['1'].weight.shape"
      ],
      "metadata": {
        "id": "6tov2FefZHmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIwBt7cJe6CH"
      },
      "source": [
        "weights = model._modules['1'].weight.detach().numpy()\n",
        "plt.figure(figsize=[10, 10])\n",
        "for i in range(10):\n",
        "    plt.subplot(5, 5, i + 1)\n",
        "    plt.title(\"Label: %i\" % i)\n",
        "    \n",
        "    plt.imshow(weights[i].reshape([28, 28]), cmap='gray');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIzsqWU_e6CL"
      },
      "source": [
        "Реализуйте Dropout-слой для полносвязной сети. Помните, что этот слой ведет себя по-разному во время обучения и во время применения. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# эту ячейку в тестах я буду сохранять в отдельный файл, поэтому не нужно\n",
        "# изменять имя класса, убирать импорты (добавлять, в принципе, можно)\n",
        "# добавлять в ячейку какой-то посторонний код, не связанный с реализацией этого класса\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class DropoutLayer(nn.Module): # не надо переименовыввать этот класс\n",
        "    \"\"\"\n",
        "    https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html\n",
        "    \"\"\"\n",
        "    def __init__(self, p=0.5, inplace=False):\n",
        "        super().__init__()\n",
        "        self.p = p\n",
        "        self.inplace = inplace\n",
        "\n",
        "    def forward(self, input):\n",
        "        # todo\n",
        "        # подсказка: скорее всего, вам понадобится ф-я rand_like https://pytorch.org/docs/stable/generated/torch.rand_like.html\n",
        "        # и masked_fill_ https://pytorch.org/docs/stable/generated/torch.Tensor.masked_fill_.html\n",
        "\n",
        "        if self.training:\n",
        "            # todo\n",
        "        else:\n",
        "            # todo\n"
      ],
      "metadata": {
        "id": "w3evQPpk4o9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "def test_dropout_train():\n",
        "\n",
        "    zero_proba = 0.9\n",
        "    do = DropoutLayer(p=zero_proba, inplace=False)\n",
        "\n",
        "    assert do.p == zero_proba, f\"zero_proba is ok\"\n",
        "\n",
        "    do.train()\n",
        "\n",
        "    input_tensor = torch.rand( (7, 3, 28, 28) )\n",
        "    input_tensor_clone = input_tensor.clone()\n",
        "\n",
        "    dropouted_tensor = do(input_tensor)\n",
        "\n",
        "    assert (input_tensor_clone == input_tensor).all(), \"input tensor was not changed\"\n",
        "\n",
        "    zeroed_values = (dropouted_tensor == 0).sum()\n",
        "    # print(\"input_tensor.numel()\", input_tensor.numel())\n",
        "    expected_zeroed_values = input_tensor.numel() * do.p\n",
        "\n",
        "    assert (zeroed_values - expected_zeroed_values).abs() < 200, f\"zeroed_values={zeroed_values} expected_zeroed_values={expected_zeroed_values}\"\n",
        "\n",
        "    input_module = input_tensor.abs().sum()\n",
        "    output_module = dropouted_tensor.abs().sum()\n",
        "    module_diff = (input_module - output_module).abs()\n",
        "    assert module_diff < 1000, f\"input_norm {input_module}, outout_norm {output_module}, diff={module_diff}\"\n",
        "\n",
        "def test_dropout_eval():\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        zero_proba = 0.9\n",
        "        do = DropoutLayer(p=zero_proba, inplace=False)\n",
        "\n",
        "        assert do.p == zero_proba, f\"zero_proba is ok\"\n",
        "\n",
        "        do.eval()\n",
        "\n",
        "        input_tensor = torch.rand( (7, 3, 28, 28) )\n",
        "        input_tensor_clone = input_tensor.clone()\n",
        "\n",
        "        dropouted_tensor = do(input_tensor)\n",
        "\n",
        "        assert (input_tensor_clone == input_tensor).all(), \"input tensor was not changed\"\n",
        "        assert (dropouted_tensor == input_tensor_clone).all(), \"output tensor equals to input\"\n",
        "\n",
        "seed_everything(42)\n",
        "\n",
        "if need_run_tests_and_training:\n",
        "    for _ in tqdm(range(100)):\n",
        "        test_dropout_train()\n",
        "        test_dropout_eval()"
      ],
      "metadata": {
        "id": "BvYygPT8y1LD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvq4PLN_e6CO"
      },
      "source": [
        "Добавьте Dropout-слой в архитектуру сети, проведите оптимизацию с параметрами, заданными ранее, визуализируйте обученные веса. Есть ли разница между весами обученными с Dropout и без него? Параметр Dropout возьмите равным 0.7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsfjKbTye6CO"
      },
      "source": [
        "modelDp = nn.Sequential(\n",
        "                    nn.Flatten(1),\n",
        "                    DropoutLayer(p=0.7),\n",
        "                    nn.Linear(28 * 28, 10),\n",
        "                    nn.LogSoftmax(dim=-1)\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMlZHpXae6CR"
      },
      "source": [
        "opt = torch.optim.Adam(modelDp.parameters(), lr=0.0005)\n",
        "train(modelDp, opt, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xzzz9Tkje6CT"
      },
      "source": [
        "weights = modelDp._modules['2'].weight.detach().numpy()\n",
        "plt.figure(figsize=[10, 10])\n",
        "for i in range(10):\n",
        "    plt.subplot(5, 5, i + 1)\n",
        "    plt.title(\"Label: %i\" % i)\n",
        "    plt.imshow(weights[i].reshape([28, 28]), cmap='gray');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5_G8wzQe6CW"
      },
      "source": [
        "Обучите еще одну модель, в которой вместо Dropout-регуляризации используется L2-регуляризация с коэффициентом 0.05. (Параметр weight_decay в оптимизаторе). Визуализируйте веса и сравните с двумя предыдущими подходами."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayzHCMx8e6CX"
      },
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Flatten(1),\n",
        "    nn.Linear(input_size,num_classes),\n",
        "    nn.LogSoftmax(dim=-1)\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWYcCBZ7e6CZ"
      },
      "source": [
        "opt = torch.optim.Adam(model.parameters(), lr=0.0005, weight_decay=0.05)\n",
        "train(model, opt, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJbA2mA3e6Cd"
      },
      "source": [
        "weights = model._modules['1'].weight.detach().numpy()\n",
        "plt.figure(figsize=[10, 10])\n",
        "for i in range(10):\n",
        "    plt.subplot(5, 5, i + 1)\n",
        "    plt.title(\"Label: %i\" % i)\n",
        "    plt.imshow(weights[i].reshape([28, 28]), cmap='gray');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKtMonw3e6Cf"
      },
      "source": [
        "## BatchNorm2d\n",
        "\n",
        "Реализуйте BatchNormalization слой для сверточной сети\n",
        "\n",
        "* `nn.Parameter` нужно использовать для того, чтобы определить обучаемые параметры для сети\n",
        "* буфферы нужно использовать для других тензоров, которые должны возвращаться в `state_dict()` модели, но для которых не нужно вычислять градиенты\n",
        "* В чем разница между register_buffer, register_parameter: [тык](https://stackoverflow.com/questions/57540745/what-is-the-difference-between-register-parameter-and-register-buffer-in-pytorch)\n",
        "* для буфферов не должны считаться градиенты, используте `.detach()` при операциях с тензорами, по которым считаются градиенты\n",
        "* Для того, чтобы заработал [broadcast](https://pytorch.org/docs/stable/notes/broadcasting.html) между тензорами разных рзаменностей, можно использовать .view(1, -1, 1, 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.arange(3).shape, torch.arange(3).view(1, -1, 1, 1).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sR3ASBhoRPf",
        "outputId": "6b2c47db-6736-44db-ede5-83ae05fc62db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3]), torch.Size([1, 3, 1, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.zeros([2, 3, 4, 4]) - torch.arange(3).view(1, -1, 1, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORr5C8JXoNlA",
        "outputId": "26e1941a-d97f-48e4-a6e3-1b2b53ad1072"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[ 0.,  0.,  0.,  0.],\n",
              "          [ 0.,  0.,  0.,  0.],\n",
              "          [ 0.,  0.,  0.,  0.],\n",
              "          [ 0.,  0.,  0.,  0.]],\n",
              "\n",
              "         [[-1., -1., -1., -1.],\n",
              "          [-1., -1., -1., -1.],\n",
              "          [-1., -1., -1., -1.],\n",
              "          [-1., -1., -1., -1.]],\n",
              "\n",
              "         [[-2., -2., -2., -2.],\n",
              "          [-2., -2., -2., -2.],\n",
              "          [-2., -2., -2., -2.],\n",
              "          [-2., -2., -2., -2.]]],\n",
              "\n",
              "\n",
              "        [[[ 0.,  0.,  0.,  0.],\n",
              "          [ 0.,  0.,  0.,  0.],\n",
              "          [ 0.,  0.,  0.,  0.],\n",
              "          [ 0.,  0.,  0.,  0.]],\n",
              "\n",
              "         [[-1., -1., -1., -1.],\n",
              "          [-1., -1., -1., -1.],\n",
              "          [-1., -1., -1., -1.],\n",
              "          [-1., -1., -1., -1.]],\n",
              "\n",
              "         [[-2., -2., -2., -2.],\n",
              "          [-2., -2., -2., -2.],\n",
              "          [-2., -2., -2., -2.],\n",
              "          [-2., -2., -2., -2.]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWvaRXmOe6Cg"
      },
      "source": [
        "# эту ячейку в тестах я буду сохранять в отдельный файл, поэтому не нужно\n",
        "# изменять имя класса, убирать импорты (добавлять, в принципе, можно)\n",
        "# добавлять в ячейку какой-то посторонний код, не связанный с реализацией этого класса\n",
        "\n",
        "from typing import Optional, Any\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class BatchNorm2dLayer(nn.Module): # не надо переименовыввать этот класс\n",
        "    \"\"\"\n",
        "    https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_features, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, device=None):\n",
        "        super().__init__()\n",
        "\n",
        "        self.eps = eps\n",
        "        self.momentum = momentum\n",
        "        self.affine = affine\n",
        "        self.num_features = num_features\n",
        "\n",
        "        self.track_running_stats = track_running_stats\n",
        "\n",
        "        if self.affine:\n",
        "            self.weight = nn.Parameter(torch.ones(num_features, device=device), requires_grad=True)\n",
        "            self.bias = nn.Parameter(torch.zeros(num_features, device=device), requires_grad=True)\n",
        "        else:\n",
        "            self.register_parameter(\"weight\", None)\n",
        "            self.register_parameter(\"bias\", None)\n",
        "\n",
        "        if self.track_running_stats:\n",
        "            self.register_buffer('running_mean', torch.zeros(num_features, device=device))\n",
        "            self.register_buffer('running_var', torch.ones(num_features, device=device))\n",
        "\n",
        "            self.register_buffer('num_batches_tracked',\n",
        "                                 torch.tensor(0, dtype=torch.long, device=device))\n",
        "\n",
        "            self.num_batches_tracked: Optional[torch.Tensor]\n",
        "        else:\n",
        "            self.register_buffer(\"running_mean\", None)\n",
        "            self.register_buffer(\"running_var\", None)\n",
        "            self.register_buffer(\"num_batches_tracked\", None)\n",
        "\n",
        "\n",
        "    def forward(self, input_tensor):\n",
        "        \n",
        "        # вычисляем mean + var по каналам для всего батча\n",
        "        # Обратите внимание на предложение в документации \"The standard-deviation is calculated via ...\"\n",
        "        # \n",
        "        # В результате должно получиться 2 тензора размерности [ self.num_features ] (средние, дисперсии для всех каналов)\n",
        "        # Обратите внимание, что mean/var принимает аргументом параметр dim: `dim is a list of dimensions, reduce over all of them.`\n",
        "        # То есть если передать список размерностей, то среднее будет считаться по всем указанным размерностям. Размерности нумеруются с нуля\n",
        "        # \n",
        "        # То есть для тензора [ batch_size, channels, width, heigth ] .mean(dim=[2, 3]) посчитает среднее значения пикселей для каждой картинке.\n",
        "        # Ваша задача усреднить по ВСЕМ картинкам и всем пикселям, нужно добавить еще одну размерность в список размерностей для усреднения\n",
        "\n",
        "        # CODE\n",
        "\n",
        "        if self.track_running_stats and self.training:\n",
        "            pass\n",
        "            # обновляем self.running_var, self.running_mean, self.num_batches_tracked\n",
        "            # Как обновить? Смотрите Note в документации BatchNorm2d\n",
        "            # не забываем сделать detach\n",
        "            # CODE\n",
        "\n",
        "        if self.track_running_stats and not self.training:\n",
        "            pass\n",
        "            # в этом случае исползуем подсчитанные во время тренировки средние значения по каналам\n",
        "            # CODE\n",
        "\n",
        "\n",
        "        # по формуле из документации нормализуем данные\n",
        "        # обратите внимание на хинты перед этой ячейкой\n",
        "        # CODE\n",
        "\n",
        "        # если есть обучаемые параметры для аффинного преобразования, делаем это преобразование\n",
        "        # тут тоже пригодятся хинты\n",
        "        # CODE\n",
        "\n",
        "        return # todo\n",
        "\n",
        "    def __repr__(self):\n",
        "        return (\n",
        "            \"BatchNorm2dLayer({num_features}, eps={eps}, momentum={momentum}, affine={affine}, \"\n",
        "            \"track_running_stats={track_running_stats})\".format(**self.__dict__)\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "def _test_batch_norm(bn, torch_bn, description=\"train\"):\n",
        "\n",
        "    batch_size = 2\n",
        "    image_size = (3, 3)\n",
        "\n",
        "    for i in range(3):\n",
        "        batch = torch.rand([ batch_size, torch_bn.num_features, *image_size ])\n",
        "        batch_clone = batch.clone()\n",
        "\n",
        "        my_bn_out    = bn.forward(batch)\n",
        "        torch_bn_out = torch_bn.forward(batch)\n",
        "\n",
        "        # print(\"my_bn_out\", my_bn_out)\n",
        "        # print(\"torch_bn_out\", torch_bn_out)\n",
        "\n",
        "        assert (batch_clone == batch).all(), \"batch was not changed inside module\"\n",
        "\n",
        "        # check buffers\n",
        "        assert torch_bn.num_batches_tracked == bn.num_batches_tracked, f\"{description}: num_batches_tracked mismatch: {torch_bn.num_batches_tracked} == {bn.num_batches_tracked}\"\n",
        "        \n",
        "        if torch_bn.track_running_stats:\n",
        "            assert bn.running_mean.requires_grad == False, \"bn.running_mean should not requires_grad. Use .detach() for per batch means\"\n",
        "            assert bn.running_var.requires_grad == False, \"bn.running_var should not requires_grad. Use .detach() for per batch vars\"\n",
        "\n",
        "            assert torch_bn.running_mean.allclose(bn.running_mean), f\"{description}: running_mean mismatch: {torch_bn.running_mean} == {bn.running_mean}\"\n",
        "            assert torch_bn.running_var.allclose(bn.running_var, rtol=0.1), f\"{description}: running_var mismatch: {torch_bn.running_var} == {bn.running_var}\"\n",
        "\n",
        "        # check parameters\n",
        "        if torch_bn.affine:\n",
        "            assert torch_bn.weight.allclose(bn.weight), f\"{description}: weight mismatch: {torch_bn.weight} == {bn.weight}\"\n",
        "            assert torch_bn.bias.allclose(bn.bias), f\"{description}: bias mismatch: {torch_bn.bias} == {bn.bias}\"\n",
        "\n",
        "        assert torch_bn_out.allclose(my_bn_out, atol=1e-04, rtol=0.1), f\"{description}: {i} torch normalized batch equals to yours one\"\n",
        "\n",
        "    return\n",
        "\n",
        "\n",
        "def test_batch_norm_2d():\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for num_channels in (1, 2, 3):\n",
        "\n",
        "            test_descr = f\"train: [channels={num_channels}]\"\n",
        "\n",
        "            bn = BatchNorm2dLayer(num_channels, track_running_stats=True).train()\n",
        "            torch_bn = nn.BatchNorm2d(num_channels, track_running_stats=True).train()\n",
        "\n",
        "            _test_batch_norm(bn, torch_bn, description=test_descr)\n",
        "\n",
        "            bn.eval()\n",
        "            torch_bn.eval()\n",
        "            \n",
        "            test_descr = f\"eval: [channels={num_channels}]\"\n",
        "            _test_batch_norm(bn, torch_bn, description=test_descr)\n",
        "        \n",
        "def test_batch_norm_2d_do_not_track_running_stats():\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for num_channels in (1, 2, 3):\n",
        "\n",
        "            test_descr = f\"train: [channels={num_channels}]\"\n",
        "\n",
        "            bn = BatchNorm2dLayer(num_channels, track_running_stats=False).train()\n",
        "            torch_bn = nn.BatchNorm2d(num_channels, track_running_stats=False).train()\n",
        "\n",
        "            _test_batch_norm(bn, torch_bn, description=test_descr)\n",
        "\n",
        "            bn.eval()\n",
        "            torch_bn.eval()\n",
        "            \n",
        "            test_descr = f\"eval: [channels={num_channels}]\"\n",
        "            _test_batch_norm(bn, torch_bn, description=test_descr)\n",
        "        \n",
        "def test_batch_norm_2d_do_not_track_running_stats_not_affine():\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for num_channels in (1, 2, 3):\n",
        "\n",
        "            test_descr = f\"train: [channels={num_channels}]\"\n",
        "\n",
        "            bn = BatchNorm2dLayer(num_channels, track_running_stats=False, affine=False).train()\n",
        "            torch_bn = nn.BatchNorm2d(num_channels, track_running_stats=False, affine=False).train()\n",
        "\n",
        "            _test_batch_norm(bn, torch_bn, description=test_descr)\n",
        "\n",
        "            bn.eval()\n",
        "            torch_bn.eval()\n",
        "            \n",
        "            test_descr = f\"eval: [channels={num_channels}]\"\n",
        "            _test_batch_norm(bn, torch_bn, description=test_descr)\n",
        "        \n",
        "\n",
        "seed_everything(42)\n",
        "\n",
        "if need_run_tests_and_training:\n",
        "    for _ in tqdm(range(100)):\n",
        "        test_batch_norm_2d()\n",
        "        test_batch_norm_2d_do_not_track_running_stats()\n",
        "        test_batch_norm_2d_do_not_track_running_stats_not_affine()"
      ],
      "metadata": {
        "id": "b3DvFg-ggTOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tpNTUWVe6Ci"
      },
      "source": [
        "Обучите сверточную сеть с batch_norm'ом"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "406kS0wFe6Co"
      },
      "source": [
        "modelBN = nn.Sequential(\n",
        "    BatchNorm2dLayer(1),\n",
        "    nn.Conv2d(1, 2, kernel_size=3, padding=1),\n",
        "    nn.ReLU(),\n",
        "    BatchNorm2dLayer(2),\n",
        "    nn.Conv2d(2, 4, kernel_size=3, padding=1),\n",
        "    nn.ReLU(),\n",
        "    BatchNorm2dLayer(4),\n",
        "    nn.Conv2d(4, 1, kernel_size=3, padding=1),\n",
        "    nn.Flatten(1),\n",
        "    nn.Linear(28 * 28 * 1, num_classes),\n",
        "    nn.LogSoftmax(dim=-1)\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uqt2bVKWe6Cq"
      },
      "source": [
        "opt = torch.optim.RMSprop(modelBN.parameters(), lr=0.01)\n",
        "train(modelBN, opt, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for m in modelBN.modules():\n",
        "    if isinstance(m, BatchNorm2dLayer):\n",
        "        print(m)\n",
        "        print(\"Parameters:\", \"weight       =\", m.weight.data,  \"bias        =\", m.bias.data)\n",
        "        print(\"Buffers:   \", \"running_mean =\", m.running_mean, \"running_var =\", m.running_var)\n",
        "        print(\"\\n\")"
      ],
      "metadata": {
        "id": "rLfxoI2zY30Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QWbPfXPyV4m4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}